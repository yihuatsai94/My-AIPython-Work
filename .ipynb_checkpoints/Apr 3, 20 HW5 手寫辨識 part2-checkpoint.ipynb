{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 讀入 MNSIT 數據集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import fashion_mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.  欣賞數據集內容"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 資料整理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.reshape(60000,28,28,1) / 255\n",
    "x_test = x_test.reshape(10000,28,28,1) / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = to_categorical(y_train, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = to_categorical(y_test, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[58926]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. 打造神經網路"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from tensorflow.keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Conv2D(16, (3,3), padding='same', input_shape=(28,28,1),activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(MaxPooling2D(pool_size=(2,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Conv2D(32, (3,3), padding='same',activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(MaxPooling2D(pool_size=(2,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Conv2D(64, (3,3), padding='same', activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(MaxPooling2D(pool_size=(2,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(54,activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(10,activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 28, 28, 16)        160       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 14, 14, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 14, 14, 32)        4640      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 7, 7, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 7, 7, 64)          18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 3, 3, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 576)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 54)                31158     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                550       \n",
      "=================================================================\n",
      "Total params: 55,004\n",
      "Trainable params: 55,004\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()\n",
    "# 看我們的神經網路"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. 組裝"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer=SGD(lr=0.094), metrics=['accuracy'])\n",
    "# 將 loss 函數從 ‘mse' 改成 'categorical_crossentropy'\n",
    "# learning rate 改成 0.094"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 28, 28, 16)        160       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 14, 14, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 14, 14, 32)        4640      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 7, 7, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 7, 7, 64)          18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 3, 3, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 576)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 54)                31158     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                550       \n",
      "=================================================================\n",
      "Total params: 55,004\n",
      "Trainable params: 55,004\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()\n",
    "# 再看一下資料"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. 訓練"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples\n",
      "Epoch 1/15\n",
      "60000/60000 [==============================] - 27s 451us/sample - loss: 0.5172 - accuracy: 0.8078\n",
      "Epoch 2/15\n",
      "60000/60000 [==============================] - 29s 485us/sample - loss: 0.3210 - accuracy: 0.8811\n",
      "Epoch 3/15\n",
      "60000/60000 [==============================] - 27s 456us/sample - loss: 0.2785 - accuracy: 0.8964\n",
      "Epoch 4/15\n",
      "60000/60000 [==============================] - 33s 551us/sample - loss: 0.2512 - accuracy: 0.9063\n",
      "Epoch 5/15\n",
      "60000/60000 [==============================] - 28s 464us/sample - loss: 0.2349 - accuracy: 0.9120\n",
      "Epoch 6/15\n",
      "60000/60000 [==============================] - 34s 561us/sample - loss: 0.2208 - accuracy: 0.9174\n",
      "Epoch 7/15\n",
      "60000/60000 [==============================] - 25s 422us/sample - loss: 0.2081 - accuracy: 0.9211\n",
      "Epoch 8/15\n",
      "60000/60000 [==============================] - 24s 401us/sample - loss: 0.1996 - accuracy: 0.9249\n",
      "Epoch 9/15\n",
      "60000/60000 [==============================] - 25s 424us/sample - loss: 0.1890 - accuracy: 0.9293\n",
      "Epoch 10/15\n",
      "60000/60000 [==============================] - 26s 436us/sample - loss: 0.1804 - accuracy: 0.9314\n",
      "Epoch 11/15\n",
      "60000/60000 [==============================] - 25s 421us/sample - loss: 0.1739 - accuracy: 0.9338\n",
      "Epoch 12/15\n",
      "60000/60000 [==============================] - 26s 428us/sample - loss: 0.1670 - accuracy: 0.9357\n",
      "Epoch 13/15\n",
      "60000/60000 [==============================] - 26s 436us/sample - loss: 0.1619 - accuracy: 0.9383\n",
      "Epoch 14/15\n",
      "60000/60000 [==============================] - 25s 409us/sample - loss: 0.1554 - accuracy: 0.9409\n",
      "Epoch 15/15\n",
      "60000/60000 [==============================] - 25s 414us/sample - loss: 0.1524 - accuracy: 0.9410\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x163634310>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, batch_size=20, epochs=15)\n",
    "# 將 epochs 改為 15 及 batch_size 改為 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以看到 batch_size 由 100 改為 20，epochs 由 20 改成 15 ，正確率可以達到 94.06%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. 預測"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = model.predict_classes(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_predict(n):\n",
    "    print('我的 Fashion CNN 預測是', class_names[result[n]])\n",
    "    X = x_test[n].reshape(28,28)\n",
    "    plt.imshow(X, cmap='Blues')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "我的 Fashion CNN 預測是 Trouser\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "my_predict(777)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import interact_manual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61714b43c9b94fd39e7d069687a05917",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=4999, description='n', max=9999), Button(description='Run Interact', sty…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.my_predict(n)>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interact_manual(my_predict, n=(0,9999))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 1s 84us/sample - loss: 0.3066 - accuracy: 0.9001\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, acc = score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The true test rate is 0.9001\n"
     ]
    }
   ],
   "source": [
    "print('The true test rate is', acc )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 修改部分\n",
    "\n",
    "1. 將 loss 函數改成 'categorical_crossentropy'\n",
    "\n",
    "2. learning rate 改成 0.094\n",
    "\n",
    "3. batch_size 改為 20（每次訓練 20 個）\n",
    "\n",
    "4. epochs 改為 15（訓練 15 次）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. 把 model 存起來"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.save('myCNNmodel.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
